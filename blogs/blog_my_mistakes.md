# 并发 (Concurrency) vs 并行 (Parallelism)

这是一个非常经典，但即使是资深工程师也容易混淆的概念。

用 Go 语言之父 **Rob Pike** 的经典名言来概括最为精准：

> **"Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once."**
>
> **并发**是关于**应付**多件事（结构上的设计）；**并行**是关于**做**多件事（物理上的执行）。

针对 CS 背景，我们从**调度视角**和**硬件视角**来拆解：

---

## 1. 核心区别：逻辑 vs 物理

### 并发 (Concurrency)
* **本质：** **逻辑上的同时**。
* **关注点：** 任务的**结构和调度**。它是一种程序设计架构，允许系统在等待一个任务（比如 I/O）的时候，去处理另一个任务。
* **实现方式：** **时间片轮转 (Time Slicing)**。
* **场景：** 即使只有 **单核 CPU**，也可以通过快速切换上下文（Context Switch），让用户感觉两个程序在“同时”运行。
* **比喻：**
    * 你是一个厨师（单核）。
    * 你切一下洋葱，然后转身去搅拌一下汤，然后再切洋葱。
    * **你同一时间只能干一件事**，但你在**应付**两道菜。

### 并行 (Parallelism)
* **本质：** **物理上的同时**。
* **关注点：** 任务的**执行效率**。它利用多核硬件，真正的在同一时刻执行多条指令。
* **实现方式：** **多核 (Multi-core) / 多机 / SIMD**。
* **场景：** 必须有 **多核 CPU** 或 **GPU**。
* **比喻：**
    * 厨房里有两个厨师（双核）。
    * 厨师 A 在切洋葱，**与此同时**，厨师 B 在搅拌汤。
    * 两件事在**物理时间上**是重叠进行的。

---

## 2. 四象限关系

理解了区别，你会发现它们是可以组合的：

1.  **并发 + 并行 (Concurrent & Parallel)：**
    * **现代主流程序。** 写了多线程代码，运行在多核 CPU 上。既有复杂的调度结构，又有物理上的同时执行。
2.  **并发 + 非并行 (Concurrent & No Parallelism)：**
    * **单核 CPU 上的多任务操作系统**。或者 **Python 的多线程**（受限于 GIL）。任务在切换，但在微观的某一纳秒，只有一个任务在跑。
3.  **非并发 + 并行 (No Concurrency & Parallelism)：**
    * **数据并行 (Data Parallelism)**。比如 GPU 渲染或者向量计算（SIMD）。
    * 你不需要复杂的线程切换逻辑，你只是单纯地对数组里的 1000 个数据同时执行 `x + 1` 的操作。逻辑很简单（单指令流），但执行是并行的（多数据流）。
4.  **非并发 + 非并行：**
    * 简单的单线程脚本：`main() { funcA(); funcB(); }`。做完 A 再做 B。

---

## 3. 结合你的技术栈理解

这个区别对理解 **Python vs C++** 的多线程差异至关重要。

### 场景 A：Python 多线程 (`threading` 库)
* **现象：** 你开了 4 个线程跑死循环计算。
* **结果：** CPU 占用率并没有变成 400%，速度也没变快，甚至可能变慢（因为切换开销）。
* **原因：** Python 有 **GIL (Global Interpreter Lock)**。同一时刻只能有一个线程在 CPU 上跑字节码。
* **结论：** Python 的多线程是 **并发的 (Concurrent)**，但通常**不是并行的 (Parallel)**。
* **用途：** 适合 **I/O 密集型**（爬虫、读写文件），因为在等待 I/O 时可以切换线程；**不适合**计算密集型。

### 场景 B：C++ / Rust / Java 多线程
* **现象：** 你开了 4 个线程跑计算。
* **结果：** 4 核 CPU 满载，速度提升接近 4 倍。
* **原因：** 没有 GIL，线程直接映射到操作系统的内核线程，OS 把它们分配给不同的 CPU 核心。
* **结论：** 既是 **并发**（逻辑独立），又是 **并行**（物理同时）。

### 场景 C：GPU 渲染 (DirectX/CUDA)
* **现象：** 几千个核心同时计算像素颜色。
* **结论：** **极致的并行**。GPU 设计的初衷就是为了 Parallelism，它甚至可能牺牲一些 Concurrency 的灵活性（比如分支预测能力很弱），只为了堆砌核心数来实现暴力并行。

---

## 总结

* **并发**是关于**程序结构**的：即使只有一个人，也要把多件事安排得井井有条。
* **并行**是关于**硬件资源**的：真的有多个人在同时干活。

> * 如果程序是为了“不阻塞用户界面”，你需要**并发**。
> * 如果程序是为了“把 1 小时的计算缩短到 10 分钟”，你需要**并行**。

# 进程 vs 线程：通信、区别与同步机制

这个问题紧承我们刚才讨论的**“分页”**和**“虚拟内存”**。

正是因为操作系统利用分页机制给每个进程分配了**独立**的虚拟地址空间，导致进程 A 看不到进程 B 的内存数据。这保证了安全，但也给通信带来了麻烦（IPC 问题）。而线程则是在同一个屋檐下，通信方式完全不同。

以下是针对 CS 毕业生的硬核总结：

---

## 一、 进程 vs 线程 (Process vs. Thread)

**一句话定义：** 可以把**进程**看作**资源分配的单位**，把**线程**看作**CPU 调度的单位**。

### 1. 核心区别表

| 维度 | 进程 (Process) | 线程 (Thread) |
| :--- | :--- | :--- |
| **内存空间** | **独立**。拥有独立的页表、堆、全局变量。 | **共享**。共享所属进程的页表、堆、全局变量。 |
| **私有资源** | 整个虚拟地址空间。 | **栈 (Stack)**、寄存器 (Registers)、程序计数器 (PC)。 |
| **切换开销** | **大**。涉及页表切换 (**TLB 刷新**)、CPU 缓存失效。 | **小**。页表不用换，TLB 不用刷，只需保存寄存器状态。 |
| **通信难度** | **难**。需要操作系统介入 (IPC)。 | **易**。直接读写共享内存 (但需要同步)。 |
| **健壮性** | **高**。一个进程崩了，不影响其他进程。 | **低**。一个线程崩了 (如野指针)，整个进程随之崩溃。 |

### 2. 面试常考：为什么线程需要私有的栈？
因为线程是**并发执行**的，每个线程都有自己的函数调用链。
* 线程 A 调用了 `func1()`
* 线程 B 调用了 `func2()`
它们的局部变量、参数和返回地址必须分开存放，否则执行流就乱套了。

---

## 二、 进程间通信 (IPC, Inter-Process Communication)

因为内存隔离，进程 A 想给进程 B 发数据，必须通过**内核 (Kernel)** 帮忙中转。

### 1. 管道 (Pipe)
* **匿名管道 (Anonymous Pipe):** `|`。只能在**父子进程**间使用（比如 shell 中的 `ps | grep`）。数据是单向流动的。
* **命名管道 (Named Pipe / FIFO):** 允许**无亲缘关系**的进程通信。
* **特点：** 本质是内核里的一个缓冲区。

### 2. 消息队列 (Message Queue)
* **机制：** 也就是链表。进程 A 把消息挂到内核的链表上，进程 B 去取。
* **优点：** 异步的，发完就走。
* **缺点：** 数据需要从用户态拷贝到内核态，再拷贝回用户态，**拷贝开销大**。

### 3. 共享内存 (Shared Memory) —— 最快的方式
* **机制：** 结合我们刚才讲的分页。
    * 进程 A 的页表项：`虚拟页 10` -> **物理页框 500**
    * 进程 B 的页表项：`虚拟页 20` -> **物理页框 500**
    * 操作系统修改页表，让两个进程的不同虚拟地址**映射到同一块物理内存**。
* **优点：** **零拷贝**。一旦建立映射，通信就像读写自己内存一样快，不需要陷入内核。
* **缺点：** 必须自己处理同步问题（比如 A 还没写完，B 就来读了），通常需要配合信号量使用。
* **场景：** 渲染引擎的多进程架构、高频交易系统。

### 4. 套接字 (Socket)
* **机制：** 通过网络协议栈通信。
* **特点：** 唯一可以**跨机器**通信的方式。哪怕在同一台机器上（Localhost）也可以用。通用性最强。

### 5. 信号 (Signal)
* **机制：** 比如 `kill -9`，`Ctrl+C`。
* **特点：** 用于通知事件，携带信息量极少。

---

## 三、 线程间通信 (Synchronization)

既然线程共享内存（Heap 和 Global Data），它们通信根本不需要“传”数据。
**线程通信的核心不是“怎么传”，而是“怎么不打架”（同步 Synchronization）。**

### 1. 共享变量 (Shared Variables)
* **方式：** 线程 A 修改全局变量 `int x`，线程 B 直接读 `x`。
* **风险：** **竞态条件 (Race Condition)**。

### 2. 锁 / 互斥量 (Mutex / Lock)
* **机制：** 保证同一时刻只有一个线程能访问共享资源。
* **例子：** `std::mutex` (C++), `threading.Lock` (Python)。

### 3. 条件变量 (Condition Variable)
* **机制：** 用于线程间的**通知/等待**机制。
* **场景：** 生产者-消费者模型。
    * 消费者线程：`wait()` (队列空了我就睡)。
    * 生产者线程：`notify()` (我放了东西，叫醒消费者起来干活)。

### 4. 信号量 (Semaphore)
* **机制：** 一个计数器，控制同时访问资源的线程数量。

---

## 四、 总结与比喻

> **进程就像是两栋不同的房子。**
> 你要和隔壁房子的人说话，不能直接穿墙。你必须打电话（Socket）、寄信（消息队列）、或者在两家中间拉一根管子（Pipe）。**最快的方法是你们两家共用一个后院（共享内存）。**

> **线程就像是住在同一栋房子里的不同房间的人。**
> 你想给室友东西，直接放在客厅（共享内存）就行了。
> **问题是：** 如果你们都想去客厅用厕所（临界区），必须锁门（Mutex），否则会发生尴尬的事情（数据竞争）。

---

## 针对你的背景建议

* **Python:** 由于 **GIL（全局解释器锁）** 的存在，Python 的多线程无法利用多核 CPU 并行计算，只能并发 IO。如果你要做计算密集型任务（如 AI 推理、图像处理），在 Python 里通常用**多进程 (Multiprocessing)** 而不是多线程。
* **C++/C:** 没有 GIL，多线程是性能优化的主力（比如渲染线程、逻辑线程分离）。
